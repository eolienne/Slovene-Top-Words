{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Slovene words\n",
    "\n",
    "## Using BeautifulSoup with Slovene\n",
    "Scrapes a page for the [2000 most frequently used words](http://bos.zrc-sazu.si/a_top2000.html) across 7 different linguistic corpora for Slovene. Then it prints a random Slovene word from this list. \n",
    "* reassign the encoding setting for requests\n",
    "* read the text into BeautifulSoup\n",
    "* extract all of the tags without attributes into a set\n",
    "\n",
    "#### What it doesn't do: \n",
    "Stemming/lemmatization of the words. Therefore some of the words are being presented with declensions that represent one of the three genders, seven cases, and/or three numbers (singular, dual, plural) in Slovene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting up my packages\n",
    "import requests, random\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in the page.  Get the table with data\n",
    "top_2000 = requests.get('http://bos.zrc-sazu.si/a_top2000.html')\n",
    "\n",
    "#The header in the HTML page says that the text encoding is ISO-8859-2. Reassign. \n",
    "top_2000.encoding = 'ISO-8859-2'\n",
    "\n",
    "#lxml is the recommended parser for BeautifulSoup\n",
    "top_2000_page = BeautifulSoup(top_2000.text,\"lxml\")\n",
    "top_2000_table = top_2000_page.find_all(\"table\")[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koliko\n"
     ]
    }
   ],
   "source": [
    "#Making a set of words from the BeautifulSoup parsed source page\n",
    "words = set()\n",
    "for td in top_2000_table.find_all(\"td\"):\n",
    "    if not td.attrs:\n",
    "        words.add(td.string.strip())\n",
    "    \n",
    "#Sorting the set by returning a list of the elements in a sorted order.\n",
    "#Special characters are put at the end\n",
    "top_words = sorted(words)\n",
    "\n",
    "#Select random word from list\n",
    "print(random.choice(top_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5528"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to extract all of the words, but this page is structured with a bunch of <td> layers. To extract all words, they are in <td> but **not** in the <td> tags that have the align attribute. See below for a sample row. It goes across all columns (seven different linguistic corpora). I don't care which corpora they're from, for this project. Here is a sample of one row from the original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "<tr><td align=right>1.<td>   je<td align=right>34920<td>   je<td align=right>58338<td>   je<td align=right>35233<td>   je<td align=right>33210<td>   je<td align=right>33483<td>   je<td align=right>27892<td>   je<td align=right>32070<td align=right>   1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors\n",
    "\n",
    "At first I saw a lot of: <code>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb9 in position 164: invalid start byte </code>\n",
    "\n",
    "Not surprising, given that Slovene uses some special characters. \n",
    "\n",
    "### Here's what didn't work\n",
    "\n",
    "* <code>top_2000_page = BeautifulSoup(top_2000.text,\"lxml\", from_encoding = \"ISO-8859-2\")</code>\n",
    "* <code>top_2000_page = BeautifulSoup(top_2000.text,\"lxml\", from_encoding = \"latin-1\") </code>\n",
    "\n",
    "Neither did trying other [possible encodings](https://docs.python.org/3.4/library/codecs.html#encodings-and-unicode): <code>utf-8, utf-16, cp852, cp1250</code>. Let's be honest, I was just guessing what might fit Central European diacritics.\n",
    "\n",
    "So I went **upstream** to the requesting the page. When I called <code>top_2000.text</code> the output looked...crazy. Not correct at all. \n",
    "\n",
    "### Here's what did work\n",
    "\n",
    "Checking the text encoding in the header. Yep. Where I should have started hours ago before getting into a much bigger rabbithole than what it seems here.\n",
    "\n",
    "<code><meta HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=ISO-8859-2\"></code>\n",
    "\n",
    "Then I tested the initial text from the request.\n",
    "<code>top_2000 = requests.get('http://bos.zrc-sazu.si/a_top2000.html')</code>\n",
    "<code>top_2000.encoding</code>\n",
    "It claimed to be ISO-8859-1, but I had a suspicion Python was lying (Thanks [StackOverflow](http://stackoverflow.com/questions/27109725/python-and-beautifulsoup-encoding-issue-from-utf-8) for corroborating with me. \n",
    "\n",
    "#### The key to unlocking the beauty of proper encoding...\n",
    "Looking at the [Requests documentation for encoding](http://docs.python-requests.org/en/latest/user/quickstart/#make-a-request). Since I knew the text was jumbled before it even got into BeautifulSoup, Requests was the logical next step to check. So I reassigned the encoding.\n",
    "\n",
    "<code>top_2000.encoding = 'ISO-8859-2'</code>\n",
    "\n",
    "After reassigning the encoding, I ran the text through BeautifulSoup, as seen above, with lxml. \n",
    "\n",
    "Then the clouds parted, the sun emerged, and I felt victorious. Beautiful beautiful characters emerged. Dobrodošli, čšž."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
